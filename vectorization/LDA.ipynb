{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA - это вероятностная модель для коллекций дискретных наборов данных, таких как текстовые корпуса. Также это тематическая модель, которая используется для обнаружения абстрактных тем из коллекции документов. Модель строит распределение Дирихле для каждой тематики с одним параметром, для каждого документа строит распределение Дирихле с другим параметром, и, в конечном счёте строит соответствия между словами из словаря корпуса и тематиками. Обзор LSI и LDA был ранее представлен в сравнительной характеристике методов векторизации:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1I4a-wPC-n3bFgrATCmp2D33UwkeczqTXHeirSiHPGFU/edit?usp=sharing\n",
    "\n",
    "Рассмотрим применение модели LDA на примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был самостоятельно собран датасет из произведений Есенина и Маяковского(по 30 стихотворений для каждого). Загрузим его и произведем частотную векторизацию(необходимо для модели LDA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(dirpath):\n",
    "    path = pathlib.Path(dirpath)\n",
    "    files = list(path.glob('*.txt'))\n",
    "    corpus = []\n",
    "    for name in files:\n",
    "        with open(name) as file:\n",
    "            corpus.append(file.read())\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esenin_path = 'dataset/esenin/'\n",
    "mayak_path = 'dataset/mayak/'\n",
    "data1 = get_corpus(esenin_path)\n",
    "data2 = get_corpus(mayak_path)\n",
    "corpus = data1 + data2\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=2000)\n",
    "X = cv.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, у нас две \"тематики\" - Есенин и Маяковский. Посмотрим, как тематики выделит LDA для данной выборки, и насколько результаты будет совпадать с точными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=2, max_iter=100, random_state=0)\n",
    "lda.fit(X)\n",
    "transformed = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([0] * 30 + [1] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(lambda pair : np.argmax(pair), transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.sum(np.where(np.equal(true_labels, labels), 1, 0)) / X.shape[0]\n",
    "precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность довольно низкая, но в данном случае это можно объяснить небольшим размером выборки. Попробуем ее улучшить с помощью вариации параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 149)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0.1, ngram_range=(1,3))\n",
    "X = cv.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=2, max_iter=100, random_state=0)\n",
    "lda.fit(X)\n",
    "transformed = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(lambda pair : np.argmax(pair), transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.sum(np.where(np.equal(true_labels, labels), 1, 0)) / X.shape[0]\n",
    "precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, алгоритм LDA позволяет получить вероятности принадлежности документа к определенным абстрактным тематикам, что можно использовать для задачи обнаружения аномальных документов(например, в классах аномальных тематик и нормальных), а также для классификации текста. Помимо этого, полученные вероятности можно использовать как векторное представление текстов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
