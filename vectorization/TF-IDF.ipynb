{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF - крайне важный метод векторизации текста. Он позволяет учитывать не только частоту токена в тексте, но и частоту его появления вообще в корпусе. С помощью данной векторизации можно рассчитывать важность слова для конкретного документа, учитывать, насколько токен делает данный документ уникальным относительно корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TfIdf = TF * IDF $$\n",
    "\n",
    "$$ TF - частота\\ слова\\ в\\ документе $$\n",
    "\n",
    "$$ IDF = log(\\frac{|D|}{|D_{word}|}) + 1 $$\n",
    "\n",
    "$$ |D|\\ -\\ количество\\ документов\\ в\\ корпусе,\\ |D_{word}|\\ -\\ количество\\ документов\\ из\\ корпуса,\\ в\\ которых\\ встретилось\\ слово\\ word$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим реализацию Tfidf из библиотеки sklearn и посмотрим, насколько векторизация соотносится с формулой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'one two',\n",
    "    'one',\n",
    "    'four one four'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'one', 'two']\n",
      "[[0.         0.43016528 0.90275015]\n",
      " [0.         1.         0.        ]\n",
      " [0.97277169 0.23176546 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(smooth_idf=False)\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one\n",
    "one = (1 / 2) * (np.log(3 / 3) + 1)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.049306144334055"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two\n",
    "two = (1 / 2) * (np.log(3 / 1) + 1)\n",
    "two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не похоже на значения первого вектора. Нормализуем вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.430165282498796"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one / (one ** 2 + two ** 2 + 0) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027501480103624"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two / (one ** 2 + two ** 2 + 0) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, TfidfVectorizer считает значения по формуле и нормализует получившийся вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем что-то похожее. Будем считать, что мы произвели частотную векторизацию(что несложно сделать с помощью CountVectorizer, либо руками посчитать вхождение токенов в текст), и теперь у нас есть соответствующая матрица признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5, 4, 3],\n",
       "       [2, 1, 0, 5],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 5, 4, 3],\n",
       "       [2, 1, 0, 5],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 5, 4, 3],\n",
       "       [2, 1, 0, 5],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 5, 4, 3]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.arange(0, 200, 5).reshape(10, 4) % 6\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tfidf:\n",
    "    def fit(self, X):\n",
    "        self.X_ = X\n",
    "    def transform(self):\n",
    "        self.tf = X_train / np.sum(X_train, axis=1)[:, None]\n",
    "        self.idf = idf = np.log(X_train.shape[0] / np.where(X_train > 0, 1, 0).sum(axis=0)) + 1\n",
    "        res = self.tf * self.idf\n",
    "        return res / (np.sum(res ** 2, axis=1) ** 0.5)[:, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.62770758, 0.68127612, 0.37662455],\n",
       "       [0.50980365, 0.1687169 , 0.        , 0.84358452],\n",
       "       [0.82327577, 0.40868835, 0.36963816, 0.13622945],\n",
       "       [0.        , 0.62770758, 0.68127612, 0.37662455],\n",
       "       [0.50980365, 0.1687169 , 0.        , 0.84358452],\n",
       "       [0.82327577, 0.40868835, 0.36963816, 0.13622945],\n",
       "       [0.        , 0.62770758, 0.68127612, 0.37662455],\n",
       "       [0.50980365, 0.1687169 , 0.        , 0.84358452],\n",
       "       [0.82327577, 0.40868835, 0.36963816, 0.13622945],\n",
       "       [0.        , 0.62770758, 0.68127612, 0.37662455]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = Tfidf()\n",
    "vect.fit(X_train)\n",
    "vect.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.41666667 0.33333333 0.25      ]\n",
      " [0.25       0.125      0.         0.625     ]\n",
      " [0.4        0.3        0.2        0.1       ]\n",
      " [0.         0.41666667 0.33333333 0.25      ]\n",
      " [0.25       0.125      0.         0.625     ]\n",
      " [0.4        0.3        0.2        0.1       ]\n",
      " [0.         0.41666667 0.33333333 0.25      ]\n",
      " [0.25       0.125      0.         0.625     ]\n",
      " [0.4        0.3        0.2        0.1       ]\n",
      " [0.         0.41666667 0.33333333 0.25      ]] \n",
      "\n",
      "[1.51082562 1.         1.35667494 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(vect.tf, '\\n')\n",
    "print(vect.idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще может TfidfVectorizer(помимо основных метод из CountVectorizer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно изменить норму, с помощью которой мы нормируем вектора. Доступны нормы l1 и l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'one', 'two']\n",
      "[[0.         0.32272511 0.67727489]\n",
      " [0.         1.         0.        ]\n",
      " [0.80758961 0.19241039 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(smooth_idf=False, norm='l1')\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно учитывать только частоту вхождения слова в документ(только tf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'one', 'two']\n",
      "[[0.         0.70710678 0.70710678]\n",
      " [0.         1.         0.        ]\n",
      " [0.89442719 0.4472136  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(smooth_idf=False, use_idf=False)\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, можно варьировать формулу для TF-IDF. Во избежание деления на близкое к нулю значение в логарифме, можно использовать параметр smooth_idf(по умолчанию используется). В данном случае к числители и знаменателю в логарифме добавляется 1:\n",
    "$$ IDF = log(\\frac{|D| + 1}{|D_{word}| + 1}) + 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'one', 'two']\n",
      "[[0.         0.70710678 0.70710678]\n",
      " [0.         1.         0.        ]\n",
      " [0.89442719 0.4472136  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(smooth_idf=True, use_idf=False)\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, можно уменьшить влияние частоты вхождения слова в документ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['four', 'one', 'two']\n",
      "[[0.         0.50854232 0.861037  ]\n",
      " [0.         1.         0.        ]\n",
      " [0.94420307 0.32936389 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(sublinear_tf=True)\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one two', 'one', 'four one four']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием этого параметра tf заменяется на 1 + log(tf), и при больших значениях tf разница будет ощутимой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в CountVectorizer и TfidfVectorizer можно учитывать n-граммы слов, учитывая n разных диапозонов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, можно учитывать только биграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'one two four',\n",
    "    'one five one five',\n",
    "    'two six seven'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['five one', 'one five', 'one two', 'six seven', 'two four', 'two six']\n",
      "[[0.         0.         0.70710678 0.         0.70710678 0.        ]\n",
      " [0.4472136  0.89442719 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.70710678 0.         0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(ngram_range=(2, 2))\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или юниграммы и биграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['five', 'five one', 'four', 'one', 'one five', 'one two', 'seven', 'six', 'six seven', 'two', 'two four', 'two six']\n",
      "[[0.         0.         0.49047908 0.37302199 0.         0.49047908\n",
      "  0.         0.         0.         0.37302199 0.49047908 0.        ]\n",
      " [0.59460647 0.29730323 0.         0.45221354 0.59460647 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.46735098 0.46735098 0.46735098 0.35543247 0.         0.46735098]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассматривать не слова, а символы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' f', ' o', ' s', ' t', 'e ', 'en', 'ev', 'fi', 'fo', 'iv', 'ix', 'ne', 'o ', 'on', 'ou', 'se', 'si', 'tw', 'ur', 've', 'wo', 'x ']\n",
      "[[0.26807016 0.         0.         0.35248004 0.26807016 0.\n",
      "  0.         0.         0.35248004 0.         0.         0.26807016\n",
      "  0.26807016 0.26807016 0.35248004 0.         0.         0.26807016\n",
      "  0.35248004 0.         0.26807016 0.        ]\n",
      " [0.31403645 0.20646009 0.         0.         0.47105467 0.\n",
      "  0.         0.41292019 0.         0.41292019 0.         0.31403645\n",
      "  0.         0.31403645 0.         0.         0.         0.\n",
      "  0.         0.31403645 0.         0.        ]\n",
      " [0.         0.         0.56995099 0.         0.         0.2849755\n",
      "  0.2849755  0.         0.         0.         0.2849755  0.\n",
      "  0.21673121 0.         0.         0.2849755  0.2849755  0.21673121\n",
      "  0.         0.21673121 0.21673121 0.2849755 ]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(analyzer='char')\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, можно рассматривать только n-граммы букв, что может быть полезно при важности учета каких-либо подстрок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'one two four',\n",
    "    'one five one five',\n",
    "    'two six seven'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' f', ' o', ' s', ' t', 'e ', 'en', 'ev', 'fi', 'fo', 'iv', 'ix', 'n ', 'ne', 'o ', 'on', 'ou', 'r ', 'se', 'si', 'tw', 'ur', 've', 'wo', 'x ']\n",
      "[[0.25066171 0.25066171 0.         0.25066171 0.25066171 0.\n",
      "  0.         0.         0.32959003 0.         0.         0.\n",
      "  0.25066171 0.25066171 0.25066171 0.32959003 0.32959003 0.\n",
      "  0.         0.25066171 0.32959003 0.         0.25066171 0.        ]\n",
      " [0.28332116 0.28332116 0.         0.         0.56664232 0.\n",
      "  0.         0.37253328 0.         0.37253328 0.         0.\n",
      "  0.28332116 0.         0.28332116 0.         0.         0.\n",
      "  0.         0.         0.         0.28332116 0.         0.        ]\n",
      " [0.         0.         0.53659627 0.20404765 0.         0.26829814\n",
      "  0.26829814 0.         0.         0.         0.26829814 0.26829814\n",
      "  0.         0.20404765 0.         0.         0.         0.26829814\n",
      "  0.26829814 0.20404765 0.         0.20404765 0.20404765 0.26829814]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
    "X = vect1.fit_transform(corpus)\n",
    "print(vect1.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение на тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим данную векторизацию к тексту Ф.М.Достоевского \"Идиот\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('idiot.txt', 'r')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на большом произведении занимает меньше секунды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 µs, sys: 1e+03 ns, total: 51 µs\n",
      "Wall time: 53.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tiv = TfidfVectorizer()\n",
    "# tiv.fit([data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем текст по строкам и отберем из них те, длина которых от 40 до 50 символов(чтобы слова были, но при этом не в огромном количестве)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = list(filter(lambda s: len(s) > 40 and len(s) < 50, data.split('\\n')))\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем данный корпус с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 690)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiv.fit(samples)\n",
    "vect = tiv.transform(samples).toarray()\n",
    "vect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем какие-нибудь предложения и немного модифицируем их для тестовых объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['— Как! — вскричал князь вне себя от удивления.',\n",
       " '— Настасью Филипповну, — пробормотал князь.',\n",
       " '— С пулями! — вскричала Настасья Филипповна.',\n",
       " '— Папенька, вас спрашивают, — крикнул Коля.',\n",
       " 'Настасья Филипповна хохотала как в истерике.']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"Князь вскричал и показал себя, на лице его было удивление!\",\n",
    "        \"Настасья Филипповна сказала, что это был князь\",\n",
    "        \"Их пулями гнали из этих мест в истерике\",\n",
    "        \"Князь Князь Князь\",\n",
    "        \"князь Князь князь князь? князь! вот это князь\",\n",
    "        \"Князь решил изучать нейросети\"]\n",
    "sent_corpus = tiv.transform(sent).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем косинусные расстояния между тестовыми объектами и всеми объектами в корпусе. Во многих случаях будет происходить деление на близкое к нулю значение, возникнет много nan-ов, которые мы заменим на единицы(максимальное расстояние). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 209)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "distances = np.array([[distance.cosine(sent_vector, input_vect) for input_vect in vect]\n",
    "                                                          for sent_vector in sent_corpus])\n",
    "distances = np.nan_to_num(distances, nan=1)\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем самые близкие по косинусному расстоянию вектора в корпусе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  32  32 185 125 206]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['— Как! — вскричал князь вне себя от удивления.',\n",
       " '— С пулями! — вскричала Настасья Филипповна.',\n",
       " '— С пулями! — вскричала Настасья Филипповна.',\n",
       " '— С Настасьей Филипповной! — вскричал князь.',\n",
       " '— Что это у вас? — спросил с беспокойством князь.',\n",
       " '— Н-ни за что! — решил князь: — ни-ни-ни!']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_ind = np.argmin(distances, axis=1)\n",
    "print(min_ind)\n",
    "[samples[ind] for ind in min_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили предложения, похожие на тестовые. Таким образом, Tfidf-векторизация действительно неплохо работает с текстами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем то же самое с CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 1.9 ms, total: 13.5 ms\n",
      "Wall time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer()\n",
    "cv.fit(samples)\n",
    "vect = cv.transform(samples).toarray()\n",
    "vect.shape\n",
    "sent = [\"Князь вскричал и показал себя, на лице его было удивление!\",\n",
    "        \"Настасья Филипповна сказала, что это был князь\",\n",
    "        \"Их пулями гнали из этих мест в истерике\",\n",
    "        \"Князь Князь Князь\",\n",
    "        \"князь Князь князь князь? князь! вот это князь\",\n",
    "        \"Князь решил изучать нейросети\"]\n",
    "sent_corpus = cv.transform(sent).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30 125  32  31  31  31]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['— Как! — вскричал князь вне себя от удивления.',\n",
       " '— Что это у вас? — спросил с беспокойством князь.',\n",
       " '— С пулями! — вскричала Настасья Филипповна.',\n",
       " '— Настасью Филипповну, — пробормотал князь.',\n",
       " '— Настасью Филипповну, — пробормотал князь.',\n",
       " '— Настасью Филипповну, — пробормотал князь.']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = np.array([[distance.cosine(sent_vector, input_vect) for input_vect in vect]\n",
    "                                                          for sent_vector in sent_corpus])\n",
    "distances = np.nan_to_num(distances, nan=1)\n",
    "min_ind = np.argmin(distances, axis=1)\n",
    "print(min_ind)\n",
    "[samples[ind] for ind in min_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что вектора, полученные с помощью частотной векторизации, дают при сравнении другие результаты, причем менее точные хотя бы с точки зрения пересечения множеств слов. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
